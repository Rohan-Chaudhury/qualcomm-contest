{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpaceInvaders Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQsuX0CsGQiq",
        "colab_type": "text"
      },
      "source": [
        "# Space Invaders\n",
        "\n",
        "# Weights & Biases x Qualcomm - SpaceInvaders Challenge\n",
        "\n",
        "This notebook contains code for loading models from a file saved in a wandb run, and evaluating the model.\n",
        "\n",
        "For more details on the SpaceInvaders challenge, please visit the [competition website](https://app.wandb.ai/wandb/spaceinvaders-challenge/benchmark/).\n",
        "\n",
        "![](https://thumbs.gfycat.com/CookedFriendlyAntarcticfurseal-size_restricted.gif)\n",
        "\n",
        "## Running this notebook\n",
        "1. Click \"Open in playground\" to create a copy of this notebook for yourself.\n",
        "2. Save a copy in Google Drive for yourself.\n",
        "3. To enable a GPU, please click Edit > Notebook Settings. Change the \"hardware accelerator\" to GPU.\n",
        "4. Step through each section, pressing play on the code blocks to run the cells.\n",
        "5. Add your own model code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlzpxEOsIePf",
        "colab_type": "text"
      },
      "source": [
        "## Load the model\n",
        "\n",
        "Please replace the model file (`model.h5`) and run_path (`username/project_name/run_name`) with your submissions model file and run_path respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrVri-RnXD2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# restore a model file from a specific run by user \"lavanyashukla\" in project \"qualcomm\" from run \"wzv0rxdj\"\n",
        "fname = \"model.h5\"\n",
        "run_path=\"lavanyashukla/qualcomm/wzv0rxdj\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkNyJEmQRWOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade wandb -qq\n",
        "# import wandb\n",
        "import wandb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maz6vvi5HlAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "4daa3697-72e6-4a35-b863-979d9c915cec"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# restore model\n",
        "wandb.restore(fname, run_path=run_path)\n",
        "best_model = open(fname, \"rb\").read()\n",
        "# agent = load_model(best_model)\n",
        "agent = load_model(fname)\n",
        "agent.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8016a2071b59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# agent = load_model(best_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(h5dict, custom_objects, compile)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot create group in read-only mode.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot create group in read-only mode."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ8AMc_zWCnS",
        "colab_type": "text"
      },
      "source": [
        "## Setup and Preproceesing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvHkMNUGGKCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gym pyvirtualdisplay -qq\n",
        "!apt-get install -y xvfb python-opengl ffmpeg -qq\n",
        "!pip install xdpyinfo -qq\n",
        "\n",
        "!apt-get update -qq\n",
        "!apt-get install cmake -qq\n",
        "!pip install --upgrade setuptools -qq\n",
        "!pip install ez_setup -qq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDpK4FdgHHsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(30)\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import os\n",
        "import cv2\n",
        "import base64\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from collections import deque\n",
        "from datetime import datetime\n",
        "import keras\n",
        "\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HN-f-hFHMeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "color = np.array([210, 164, 74]).mean()\n",
        "\n",
        "def preprocess_frame(obs):\n",
        "    # Crop and resize\n",
        "    img = obs[25:201:2, ::2]\n",
        "\n",
        "    # Convert to greyscale\n",
        "    img = img.mean(axis=2)\n",
        "\n",
        "    # Improve contrast\n",
        "    img[img==color] = 0\n",
        "\n",
        "    # Normalzie image\n",
        "    img = (img - 128) / 128 - 1\n",
        "\n",
        "    # Reshape to 80*80*1\n",
        "    img = img.reshape(88,80)\n",
        "\n",
        "    return img "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwt-wy0NWHuH",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIZiiAW6HTil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# **** Caution: Do not modify this cell ****\n",
        "# initialize total reward across episodes\n",
        "cumulative_reward = 0\n",
        "episode = 0\n",
        "\n",
        "def evaluate(episodic_reward):\n",
        "  '''\n",
        "  Takes in the reward for an episode, calculates the cumulative_avg_reward\n",
        "    and logs it in wandb. If episode > 100, stops logging scores to wandb.\n",
        "    Called after playing each episode. See example below.\n",
        "\n",
        "  Arguments:\n",
        "    episodic_reward - reward received after playing current episode\n",
        "  '''\n",
        "  global episode\n",
        "  global cumulative_reward\n",
        "  episode += 1\n",
        "  print(\"Episode: %d\"%(episode))\n",
        "\n",
        "  # your models will be evaluated on 100-episode average reward\n",
        "  # therefore, we stop logging after 100 episodes\n",
        "  if (episode > 100):\n",
        "    print(\"Scores from episodes > 100 won't be logged in wandb.\")\n",
        "    return\n",
        "\n",
        "  # log total reward received in this episode to wandb\n",
        "  wandb.log({'episodic_reward': episodic_reward})\n",
        "\n",
        "  # add reward from this episode to cumulative_reward\n",
        "  cumulative_reward += episodic_reward\n",
        "\n",
        "  # calculate the cumulative_avg_reward\n",
        "  # this is the metric your models will be evaluated on\n",
        "  cumulative_avg_reward = cumulative_reward/episode\n",
        "\n",
        "  # log cumulative_avg_reward over all episodes played so far\n",
        "  wandb.log({'cumulative_avg_reward': cumulative_avg_reward})\n",
        "\n",
        "  return cumulative_avg_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDCVUIhxWL-n",
        "colab_type": "text"
      },
      "source": [
        "## Play the game for 100 episodes, log cumulative average reward, for 5 different values of seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHyYmf2AHWBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import seed\n",
        "from tensorflow import set_random_seed\n",
        "\n",
        "cumulative_avg_rewards = []\n",
        "for seed in [10, 50, 100, 200, 500]:\n",
        "  seed(seed)\n",
        "  set_random_seed(seed)\n",
        "\n",
        "  # initialize environment\n",
        "  env = gym.make('SpaceInvaders-v0')\n",
        "  state_size = env.observation_space.shape[0]\n",
        "  action_size = env.action_space.n\n",
        "  print(\"Actions available(%d): %r\"%(env.action_space.n, env.env.get_action_meanings()))\n",
        "\n",
        "  # initialize a new wandb run\n",
        "  wandb.init(project=\"qualcomm-evaluation\")\n",
        "\n",
        "  # define hyperparameters\n",
        "  wandb.config.episodes = 100\n",
        "  wandb.config.runpath = run_path\n",
        "  input_shape = (None, 88, 80, 1)\n",
        "\n",
        "  # record gameplay video\n",
        "  display = Display(visible=0, size=(1400, 900))\n",
        "  display.start()\n",
        "\n",
        "  # run for 100 episodes\n",
        "  for i in range(wandb.config.episodes):\n",
        "    # Set reward received in this episode = 0 at the start of the episode\n",
        "    episodic_reward = 0\n",
        "\n",
        "    # record a video of the game using wrapper\n",
        "    env = gym.wrappers.Monitor(env, './video', force=True)\n",
        "    \n",
        "    # play a random game\n",
        "    state = env.reset()\n",
        "    state = preprocess_frame(state)\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "      # get prediction for next action from model\n",
        "      action = agent.act(state)\n",
        "\n",
        "      # perform the action and fetch next state, reward\n",
        "      next_state, reward, done, _ = env.step(action)\n",
        "      next_state = preprocess_frame(next_state)\n",
        "      agent.remember(state, action, reward, next_state, done)\n",
        "      state = next_state\n",
        "\n",
        "      episodic_reward += reward\n",
        "    \n",
        "    # call evaluation function - takes in reward received after playing an episode\n",
        "    # calculates the cumulative_avg_reward over 100 episodes & logs it in wandb\n",
        "    cumulative_avg_reward = evaluate(episodic_reward)\n",
        "\n",
        "    # your models will be evaluated on 100-episode average reward\n",
        "    # therefore, we stop logging after 100 episodes\n",
        "    if (i == 99):\n",
        "      cumulative_avg_rewards.append(cumulative_avg_reward)\n",
        "      break\n",
        "\n",
        "    record_video = False\n",
        "    env.close() \n",
        "\n",
        "    # render gameplay video\n",
        "    if (i %50 == 0):\n",
        "      mp4list = glob.glob('video/*.mp4')\n",
        "      if len(mp4list) > 0:\n",
        "        print(len(mp4list))\n",
        "        mp4 = mp4list[-1]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "\n",
        "        # log gameplay video in wandb\n",
        "        wandb.log({\"gameplays\": wandb.Video(mp4, fps=4, format=\"gif\")})\n",
        "\n",
        "        # display gameplay video\n",
        "        ipythondisplay.display(HTML(data='''<video alt=\"\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(encoded.decode('ascii'))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV-irjWcYDAE",
        "colab_type": "text"
      },
      "source": [
        "# Final score\n",
        "The final score is evaluated as the cumulative_avg_reward, averaged across 5 seeds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKiJcC0WJ4W-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Final score: \", np.mean(cumulative_avg_rewards))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
